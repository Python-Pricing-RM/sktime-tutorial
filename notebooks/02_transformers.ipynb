{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of this notebook\n",
    "\n",
    "* why transformers? transformers in `sktime`\n",
    "\n",
    "    * transformers = modular data processing steps\n",
    "    * simple pipeline example & transformer explained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* overview of transformer features\n",
    "\n",
    "    * types of transformers - input types, output types\n",
    "    * broadcasting/vectorization to panel, hierarchical, multivariate\n",
    "    * searching for transformers using `all_estimators`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for easy local use of this notebook\n",
    "from os import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Transformers in `sktime`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Wherefore transformers?\n",
    "\n",
    "or: why sktime transformers will improve your life!\n",
    "\n",
    "(disclaimer: not the same product as deep learning transformers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "suppose we want to forecast this well-known dataset\n",
    "(airline passengers by year in a fixed scope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_airline\n",
    "from sktime.utils.plotting import plot_series\n",
    "\n",
    "y = load_airline()\n",
    "plot_series(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "observations:\n",
    "\n",
    "* there is seasonal periodicity, 12 month period\n",
    "* seasonal periodicity looks multiplicative (not additive) to trend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "idea: forecast might be easier\n",
    "\n",
    "* with seasonality removed\n",
    "* on logarithmic value scale (multiplication becomes addition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive approach - don't do this at home!\n",
    "\n",
    "Maybe doing this manually step by step is a good idea?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# compute the logarithm\n",
    "logy = np.log(y)\n",
    "\n",
    "plot_series(logy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this looks additive now!\n",
    "\n",
    "ok, what next - deaseasonalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# apply this to y\n",
    "# wait no, to logy\n",
    "\n",
    "seasonal_result = seasonal_decompose(logy, period=12)\n",
    "\n",
    "trend = seasonal_result.trend\n",
    "resid = seasonal_result.resid\n",
    "seasonal = seasonal_result.seasonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_series(trend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_series(seasonal, resid, labels=[\"seasonal component\", \"residual component\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok, now the forecast!\n",
    "\n",
    "... of what ??\n",
    "\n",
    "ah yes, residual plus trend, because seasonal just repeats itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecast this:\n",
    "plot_series(trend + resid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this has nans??\n",
    "trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok, forecast this instead then:\n",
    "y_to_forecast = logy - seasonal\n",
    "\n",
    "# phew, no nans!\n",
    "y_to_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.trend import PolynomialTrendForecaster\n",
    "\n",
    "f = PolynomialTrendForecaster(degree=2)\n",
    "f.fit(y_to_forecast, fh=list(range(1, 13)))\n",
    "y_fcst = f.predict()\n",
    "\n",
    "plot_series(y_to_forecast, y_fcst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "looks reasonable!\n",
    "\n",
    "Now to turn this into a forecast of the original y ...\n",
    "\n",
    "* add seasonal\n",
    "* invert the logarithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_fcst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_fcst_orig = y_fcst + seasonal[0:12]\n",
    "y_fcst_orig_orig = np.exp(y_fcst_orig)\n",
    "\n",
    "y_fcst_orig_orig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok, that did not work. Something something pandas indices??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_fcst_orig = y_fcst + seasonal[0:12].values\n",
    "y_fcst_orig_orig = np.exp(y_fcst_orig)\n",
    "\n",
    "plot_series(y, y_fcst_orig_orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok, done! and it only took us 10 years.\n",
    "\n",
    "Maybe there is a better way?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slightly less naive approach - use `sktime` transformers (badly)\n",
    "\n",
    "Ok, surely there is a way where I don't have to fiddle with wildly varying interfaces of every step.\n",
    "\n",
    "Solution: use transformers!\n",
    "\n",
    "Same interface at every step!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.trend import PolynomialTrendForecaster\n",
    "from sktime.transformations.series.boxcox import LogTransformer\n",
    "from sktime.transformations.series.detrend import Deseasonalizer\n",
    "\n",
    "\n",
    "y = load_airline()\n",
    "\n",
    "t_log = LogTransformer()\n",
    "ylog = t_log.fit_transform(y)\n",
    "\n",
    "t_deseason = Deseasonalizer(sp=12)\n",
    "y_deseason = t_deseason.fit_transform(ylog)\n",
    "\n",
    "f = PolynomialTrendForecaster(degree=2)\n",
    "f.fit(y_deseason, fh=list(range(1,13)))\n",
    "y_fcst = f.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hm, but now we need to invert the transformations...\n",
    "\n",
    "fortunately transformers have an inverse transform, standard interface point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_fcst_orig = t_deseason.inverse_transform(y_fcst)\n",
    "# the deseasonalizer remembered the seasonality component! nice!\n",
    "\n",
    "y_fcst_orig_orig = t_log.inverse_transform(y_fcst_orig)\n",
    "\n",
    "plot_series(y, y_fcst_orig_orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expert approach - use `sktime` transformers with pipelines!\n",
    "\n",
    "Bragging rights included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.trend import PolynomialTrendForecaster\n",
    "from sktime.transformations.series.boxcox import LogTransformer\n",
    "from sktime.transformations.series.detrend import Deseasonalizer\n",
    "\n",
    "y = load_airline()\n",
    "\n",
    "f = LogTransformer() * Deseasonalizer(sp=12) * PolynomialTrendForecaster(degree=2)\n",
    "\n",
    "f.fit(y, fh=list(range(1,13)))\n",
    "y_fcst = f.predict()\n",
    "\n",
    "plot_series(y, y_fcst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what happened here?\n",
    "\n",
    "The \"chain\" operator `*` creates a \"forecasting pipeline\"\n",
    "\n",
    "Has the same interface as all other forecasters! No additional data fiddling!\n",
    "\n",
    "Transformers \"slot in\" as standardized components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at this in more detail:\n",
    "\n",
    "* `sktime` transformers interface\n",
    "* `sktime` pipeline building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 What are transformers? <a class=\"anchor\" id=\"section_1_1\"></a>\n",
    "\n",
    "Transformer = modulari data processing steps commonly used in machine learning\n",
    "\n",
    "(\"transformer\" used in the sense of `scikit-learn`)\n",
    "\n",
    "Transformers are estimators that:\n",
    "\n",
    "* are fitted to a batch of data via `fit(data)`, changing its state\n",
    "* are applied to another batch of data via `transform(X)`, producing transformed data\n",
    "* may have an `inverse_transform(X)`\n",
    "\n",
    "In `sktime`, input `X` to `fit` and `transform` is typically a time series or a panel (collection of time series)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic use of an `sktime` time series transformer is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. prepare the data\n",
    "from sktime.utils._testing.series import _make_series\n",
    "\n",
    "X = _make_series()\n",
    "X_train = X[:30]\n",
    "X_test = X[30:]\n",
    "# X_train and X_test are both pandas.Series\n",
    "\n",
    "X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. construct the transformer\n",
    "from sktime.transformations.series.boxcox import BoxCoxTransformer\n",
    "\n",
    "# trafo is an sktime estimator inheriting from BaseTransformer\n",
    "# Box-Cox transform with lambda parameter fitted via mle\n",
    "trafo = BoxCoxTransformer(method=\"mle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. fit the transformer to training data\n",
    "trafo.fit(X_train)\n",
    "\n",
    "# 4. apply the transformer to transform test data\n",
    "# Box-Cox transform with lambda fitted on X_train\n",
    "X_transformed = trafo.transform(X_test)\n",
    "\n",
    "X_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the training and test set is the same, step 3 and 4 can be carried out more concisely (and sometimes more efficiently) by using `fit_transform`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3+4. apply the transformer to fit and transform on the same data, X\n",
    "X_transformed = trafo.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Different types of transformers <a class=\"anchor\" id=\"section_1_2\"></a>\n",
    "\n",
    "`sktime` distinguishes different types of transformer, depending on the input type of `fit` and `transform`, and the output type of `transform`.\n",
    "\n",
    "Transformers differ by:\n",
    "\n",
    "* making use of an additional `y` argument in `fit` or `transform`\n",
    "* whether the input to `fit` and `transform` is a single time series, a collection of time series, or scalar values (data frame row)\n",
    "* whether the output of `transform` is a single time series, a collection of time series, or scalar values (data frame row)\n",
    "* whether the input to `fit` and `transform` are one object or two. Two objects as input and a scalar output means the transformer is a distance or kernel function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More detail on this is given in [Section 2](#chapter2).\n",
    "\n",
    "To illustrate the difference, we compare two transformers with different output:\n",
    "\n",
    "* the Box-Cox transformer `BoxCoxTrannsformer`, which transforms a time series to a time series\n",
    "* the summary transformer `SummaryTransformer`, which transforms a time series to scalars such as the mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constructing the transformer\n",
    "from sktime.transformations.series.boxcox import BoxCoxTransformer\n",
    "from sktime.transformations.series.summarize import SummaryTransformer\n",
    "from sktime.utils._testing.series import _make_series\n",
    "\n",
    "# getting some data\n",
    "# this is one pandas.Series\n",
    "X = _make_series(n_timepoints=10)\n",
    "\n",
    "# constructing the transformers\n",
    "boxcox_trafo = BoxCoxTransformer(method=\"mle\")\n",
    "summary_trafo = SummaryTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this produces a pandas Series\n",
    "boxcox_trafo.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this produces a pandas.DataFrame row\n",
    "summary_trafo.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For time series transformers, the metadata tags describe the expected output of `transform`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxcox_trafo.get_tag(\"scitype:transform-output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_trafo.get_tag(\"scitype:transform-output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find transformers, use `all_estimators` and filter by tags:\n",
    "\n",
    "* `\"scitype:transform-output\"` - the output scitype. `Series` for time series, `Primitives` for primitive features (float, categories), `Panel` for collections of time series.\n",
    "* `\"scitype:transform-input\"` - the input scitype. `Series` for time series.\n",
    "* `\"scitype:instancewise\"` - If `True`, vectorized operation per series. If `False`, uses multiple time series non-trivially."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: find all transformers that output time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.registry import all_estimators\n",
    "\n",
    "# now subset to transformers that extract scalar features\n",
    "all_estimators(\n",
    "    \"transformer\",\n",
    "    as_dataframe=True,\n",
    "    filter_tags={\"scitype:transform-output\": \"Series\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more complete overview on transformer types and tags is given in the `sktime` transformers tutorial.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Broadcasting aka vectorization of transformers <a class=\"anchor\" id=\"section_1_3\"></a>\n",
    "\n",
    "`sktime` transformers may be natively univariate, or apply only to a single time series.\n",
    "\n",
    "Even if this is the case, they broadcast across variables and instances of time series, where applicable (als known as vectorization in `numpy` parlance).\n",
    "\n",
    "This ensures that all `sktime` transformers can be applied to multivariate and multi-instance (panel, hierarchical) time series data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 1: broadcasting/vectorization of time series to time series transformer\n",
    "\n",
    "The `BoxCoxTransformer` from previous sections applies to single instances of univariate time series. When multiple instances or variables are seen, it broadcasts across both:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.transformations.series.boxcox import BoxCoxTransformer\n",
    "from sktime.utils._testing.hierarchical import _make_hierarchical\n",
    "\n",
    "# hierarchical data with 2 variables and 2 levels\n",
    "X = _make_hierarchical(n_columns=2)\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constructing the transformers\n",
    "boxcox_trafo = BoxCoxTransformer(method=\"mle\")\n",
    "\n",
    "# applying to X results in hierarchical data\n",
    "boxcox_trafo.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitted model components of vectorized transformers can be found in the `transformers_` attribute, or accessed via the universal `get_fitted_params` interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxcox_trafo.transformers_\n",
    "# this is a pandas.DataFrame that contains the fitted transformers\n",
    "# one per time series instance and variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxcox_trafo.get_fitted_params()\n",
    "# this returns a dictionary\n",
    "# the transformers DataFrame is available at the key \"transformers\"\n",
    "# individual transformers are available at dataframe-like keys\n",
    "# it also contains all fitted lambdas as keyed parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 2: broadcasting/vectorization of time series to scalar features transformer\n",
    "\n",
    "The `SummaryTransformer` behaves similarly.\n",
    "Multiple time series instances are transformed to different columns of the resulting data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.transformations.series.summarize import SummaryTransformer\n",
    "\n",
    "summary_trafo = SummaryTransformer()\n",
    "\n",
    "# this produces a pandas DataFrame with more rows and columns\n",
    "# rows correspond to different instances in X\n",
    "# columns are multiplied and names prefixed by [variablename]__\n",
    "# there is one column per variable and transformed feature\n",
    "summary_trafo.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Transformers as pipeline components <a class=\"anchor\" id=\"section_1_4\"></a>\n",
    "\n",
    "`sktime` transformers can be pipelined with any other `sktime` estimator type, including forecasters, classifiers, and other transformers.\n",
    "\n",
    "Pipelines = estimators of the same type, same interface as specialized class\n",
    "\n",
    "pipeline build operation: `make_pipeline` or via `*` dunder\n",
    "\n",
    "Pipelining `pipe = trafo * est` produces `pipe` of same type as `est`.\n",
    "\n",
    "In `pipe.fit`, first `trafo.fit_transform`, then `est.fit` is executed on the result.\n",
    "\n",
    "In `pipe.predict`, first `trafo.transform`, then `est.predict` is executed.\n",
    "\n",
    "(the arguments that are piped differ by type and can be looked up in the docstrings of pipeline classes, or specialized tutorials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1: forecaster pipeline\n",
    "\n",
    "we have seen this example above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.trend import PolynomialTrendForecaster\n",
    "from sktime.transformations.series.boxcox import LogTransformer\n",
    "from sktime.transformations.series.detrend import Deseasonalizer\n",
    "\n",
    "y = load_airline()\n",
    "\n",
    "pipe = LogTransformer() * Deseasonalizer(sp=12) * PolynomialTrendForecaster(degree=2)\n",
    "\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a forecaster with the same interface as Polynomial Trend Forecaster\n",
    "pipe.fit(y, fh=[1, 2, 3])\n",
    "y_pred = pipe.predict()\n",
    "\n",
    "plot_series(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 2: classifier pipeline\n",
    "\n",
    "works the same with classifiers or other estimator types!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
    "from sktime.transformations.series.exponent import ExponentTransformer\n",
    "\n",
    "pipe = ExponentTransformer() * KNeighborsTimeSeriesClassifier()\n",
    "\n",
    "# this constructs a ClassifierPipeline, which is also a classifier\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_unit_test\n",
    "\n",
    "X_train, y_train = load_unit_test(split=\"TRAIN\")\n",
    "X_test, _ = load_unit_test(split=\"TEST\")\n",
    "\n",
    "# this is a forecaster with the same interface as knn-classifier\n",
    "# first applies exponent transform, then knn-classifier\n",
    "pipe.fit(X_train, y_train)\n",
    "pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Combining transformers, feature engineering\n",
    "\n",
    "transformers are natural pipeline components\n",
    "\n",
    "* data processing steps\n",
    "* feature engineering steps\n",
    "* post processing steps\n",
    "\n",
    "they can be combined in a number of other ways:\n",
    "\n",
    "* pipelining = sequential chaining\n",
    "* feature union = parallel, addition of features\n",
    "* feature subsetting = selecting columns\n",
    "* inversion = switch transform and inverse\n",
    "* multiplexing = switching between transformers\n",
    "* passthrough = switch on/ off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chaining transformers via `*`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.transformations.series.difference import Differencer\n",
    "from sktime.transformations.series.summarize import SummaryTransformer\n",
    "\n",
    "pipe = Differencer() * SummaryTransformer()\n",
    "\n",
    "# this constructs a TransformerPipeline, which is also a transformer\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.utils._testing.hierarchical import _bottom_hier_datagen\n",
    "\n",
    "X = _bottom_hier_datagen(no_levels=1, no_bottom_nodes=2)\n",
    "\n",
    "# this is a transformer with the same interface\n",
    "# first applies differencer, then summary transform\n",
    "pipe.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compatible with sklearn transformers!\n",
    "\n",
    "default applies sklearn transformer per individual time series as a data frame table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pipe = Differencer() * StandardScaler()\n",
    "\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pipeline-adaptor chains can be constructed manually:\n",
    "\n",
    "* `sktime.transformations.compose.TransformerPipeline`\n",
    "* `sktime.transformations.series.adapt.TabularToSeriesAdaptor` for `sklearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "composites are compatible with `get_params` / `set_params` parameter interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature union via `+`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.transformations.series.difference import Differencer\n",
    "from sktime.transformations.series.lag import Lag\n",
    "\n",
    "pipe = Differencer() + Lag()\n",
    "\n",
    "# this constructs a FeatureUnion, which is also a transformer\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.utils._testing.hierarchical import _bottom_hier_datagen\n",
    "\n",
    "X = _bottom_hier_datagen(no_levels=1, no_bottom_nodes=2)\n",
    "\n",
    "# applies both Differencer and Lag, returns transformed in different columns\n",
    "pipe.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to retain the original columns, use the `Id` transformer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.transformations.compose import Id\n",
    "from sktime.transformations.series.difference import Differencer\n",
    "from sktime.transformations.series.lag import Lag\n",
    "\n",
    "pipe = Id() + Differencer() + Lag([1, 2], index_out=\"original\")\n",
    "\n",
    "pipe.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter inspection\n",
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset input columns via `[colname]`\n",
    "\n",
    "let's say we want to apply `Differencer` to column 0, and `Lag` to column 1\n",
    "\n",
    "also we keep the original columns for illustration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.utils._testing.hierarchical import _make_hierarchical\n",
    "\n",
    "X = _make_hierarchical(\n",
    "    hierarchy_levels=(2, 2), n_columns=2, min_timepoints=3, max_timepoints=3\n",
    ")\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.transformations.compose import Id\n",
    "from sktime.transformations.series.difference import Differencer\n",
    "from sktime.transformations.series.lag import Lag\n",
    "\n",
    "pipe = Id() + Differencer()[\"c0\"] + Lag([1, 2], index_out=\"original\")[\"c1\"]\n",
    "\n",
    "pipe.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "auto-generated names can be replaced by using `FeatureUnion` explicitly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.transformations.compose import FeatureUnion\n",
    "\n",
    "pipe = FeatureUnion(\n",
    "    [\n",
    "        (\"original\", Id()),\n",
    "        (\"diff\", Differencer()[\"c0\"]),\n",
    "        (\"lag\", Lag([1, 2], index_out=\"original\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### turning log transform into exp transform via invert `~`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sktime.transformations.series.boxcox import LogTransformer\n",
    "\n",
    "log = LogTransformer()\n",
    "\n",
    "exp = ~log\n",
    "\n",
    "# this behaves like an \"e to the power of\" transformer now\n",
    "exp.fit_transform(np.array([1, 2, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### autoML structure compositors: multiplexer switch `¦` and on/off switch `-`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "expose decisions as parameter\n",
    "\n",
    "* do we want differencer *or* lag? for tuning later\n",
    "* do we want [differencer and lag] or [original features and lag] ? for tuning later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# differencer or lag\n",
    "\n",
    "from sktime.transformations.series.difference import Differencer\n",
    "from sktime.transformations.series.lag import Lag\n",
    "\n",
    "pipe = Differencer() | Lag()\n",
    "\n",
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the `selected_transformer` parameter exposes the choice:\n",
    "\n",
    "does this behave as `Lag` or `Differencer`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# switch = Lag -> this is a Lag transformer now!\n",
    "pipe.set_params(selected_transformer=\"Lag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# switch = Lag -> this is a Differencer now!\n",
    "pipe.set_params(selected_transformer=\"Differencer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "similar, on/off switch with `~`\n",
    "\n",
    "same as multiplexer between wrapped transformer and `Id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optional_differencer = - Differencer()\n",
    "\n",
    "# this behaves as Differencer now\n",
    "optional_differencer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is now just the identity transformer\n",
    "optional_differencer.set_params(passthrough=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see more later in part 3 on how to use this with tuning for full structural AutoML!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dunders glossary\n",
    "\n",
    "| Type | Dunder | Meaning | `sktime` class |\n",
    "| --- | --- | --- | --- |\n",
    "| compose | `*` | chaining/pipeline - also works with other estimator types | type dependent |\n",
    "| compose | `**` | chaining to secondary input of another estimator | type dependent |\n",
    "| compose | `+` | feature union | `FeatureUnion` |\n",
    "| interface | `~` | invert | `InvertTransform` |\n",
    "| structural | `¦` | multiplexing (\"switch\") | type dependent |\n",
    "| structural | `-` | optional passthrough (\"on/off\") | `OptionalPassthrough` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### selected useful transformers, compositors, adapters\n",
    "\n",
    "* delay fitting to `transform` via `sktime.transformations.compose.FitInTransform`\n",
    "* any `pandas` method via `sktime.transformations.compose.adapt.PandasTransformAdaptor`\n",
    "* date/time features via `sktime.transformations.series.date.DateTimeFeatures`\n",
    "* lags via `transformations.series.lag.Lag`\n",
    "* differences, first and n-th, via `transformations.series.difference.Differencer`\n",
    "* scaled logit via `transformations.series.scaledlogit.ScaledLogitTransform`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer type glossary\n",
    "\n",
    "Common types of transformation in `sktime`:\n",
    "\n",
    "| from | to | base class | examples (sci) | examples (`sktime`) |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| time series | scalar features | `BaseTransformer` (`Primitives` output) | `tsfresh`, or 7-number-summary | `Catch22`, `SummaryTransformer` |\n",
    "| time series | time series | `BaseTransformer` (`Series`, `instancewise`)  | detrending, smoothing, filtering, lagging | `Detrender`, `Differencer`, `Lag`, `Filter` |\n",
    "| time series panel | also a panel | `BaseTransformer` (`Series` output)  | principal component projection | `PCATransformer`, `PaddingTransformer` |\n",
    "| two feature vectors | a scalar | `BasePairwiseTransformer` | Euclidean distance, L1 distance | `ScipyDist`, `AggrDist`, `FlatDist` |\n",
    "| two time series | a scalar | `BasePairwiseTransformerPanel` | DTW distance, alignment kernel | `DtwDist`, `EditDist` |\n",
    "\n",
    "first three = \"time series transformers\", or, simply, \"transformers\"\n",
    "\n",
    "all \"transformers\" follow the same base interface.\n",
    "\n",
    "\"pairwise transformers\" have separate base interface (due to two inputs)\n",
    "\n",
    "include distances and kernels between time series or feature vectors\n",
    "\n",
    "all inherit `BaseObject` and follow unified `skbase` interface with `get_params`, `get_fitted_params`, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Summary<a class=\"anchor\" id=\"chapter5\"></a>\n",
    "\n",
    "* `sktime` comes with transformation algorithms (or transformers), all of which share a common interface. The interface is fully interoperable with the `scikit-learn` interface.\n",
    "\n",
    "* Transformers exist in several categories: series being transformed to series; series being transformed to primitive features (floats, categories); pairwise transformers where pairs of series or vectors are transformed to a float output, such as distance functions and kernel functions.\n",
    "\n",
    "* Transformers are typically used as components of other algorithms across learning tasks, for instance as feature extraction steps in pipelines, or as distances in a distance-based classification algorithm. Composition using `sktime` transformers is fully modular.\n",
    "\n",
    "* `sktime` provides easy-to-use extension templates for all the above."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3.8.12 ('sktime-baseobject')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "ff39becaf9fb8fe58d1d34fc2c63ee411a5dd80719d9cd02520236b9e8461a42"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
